{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Deep Learning with Keras Lab on Titanic Dataset\n",
    "\n",
    "In this notebook.\n",
    "We will gonna learn some basics in keras & How we gonna build our model using their APIs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### What & Why Keras ?\n",
    "\n",
    "Keras is an API designed for human beings, not machines.\n",
    "Keras follows best practices for reducing cognitive load: it offers consistent & simple APIs.\n",
    "This makes Keras easy to learn and easy to use.\n",
    "This ease of use does not come at the cost of reduced flexibility:\n",
    "because Keras integrates with lower-level deep learning languages (in particular TensorFlow),\n",
    "it enables you to implement anything you could have built in the base language."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Titanic Dataset\n",
    "\n",
    "The sinking of the Titanic is one of the most infamous shipwrecks in history.\n",
    "While there was some element of luck involved in surviving,\n",
    "it seems some groups of people were more likely to survive than others.\n",
    "In this problem, we ask you to build a predictive model that answers the question: \n",
    "“what sorts of people were more likely to survive?” \n",
    "using passenger data (ie name, age, gender, socio-economic class, etc).\n",
    "\n",
    "##### Let's read and explore our data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np # numpy library used mainly for linear algebra\n",
    "import pandas as pd # pandas library used to read and manipulate tabular data\n",
    "\n",
    "# define random seed for reproducibility we will use it in other instances in the code\n",
    "seed = 17\n",
    "np.random.seed(seed)\n",
    "\n",
    "# load our data\n",
    "root_dir = \"datasets/titanic/\" # the root directory of the dataset\n",
    "df_train = pd.read_csv(root_dir + \"train.csv\") # load training data\n",
    "df_test = pd.read_csv(root_dir + \"test.csv\", index_col='PassengerId') # load testing data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### Visualize the training dataframe and get some insights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0            1         0       3   \n",
       "1            2         1       1   \n",
       "2            3         1       3   \n",
       "3            4         1       1   \n",
       "4            5         0       3   \n",
       "\n",
       "                                                Name     Sex   Age  SibSp  \\\n",
       "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
       "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
       "4                           Allen, Mr. William Henry    male  35.0      0   \n",
       "\n",
       "   Parch            Ticket     Fare Cabin Embarked  \n",
       "0      0         A/5 21171   7.2500   NaN        S  \n",
       "1      0          PC 17599  71.2833   C85        C  \n",
       "2      0  STON/O2. 3101282   7.9250   NaN        S  \n",
       "3      0            113803  53.1000  C123        S  \n",
       "4      0            373450   8.0500   NaN        S  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# preview the training data\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PassengerId      0\n",
       "Survived         0\n",
       "Pclass           0\n",
       "Name             0\n",
       "Sex              0\n",
       "Age            177\n",
       "SibSp            0\n",
       "Parch            0\n",
       "Ticket           0\n",
       "Fare             0\n",
       "Cabin          687\n",
       "Embarked         2\n",
       "dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Show that there is NaN data (Age,Fare Embarked), that needs to be handled during data cleaning\n",
    "df_train.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Cleaning and processing\n",
    "\n",
    "- As you see there is NaN data in the training data frame which we should take care of and clean the data properly\n",
    "- We need to drop columns we don't need to use it as features\n",
    "- We need to fill the missing data in Age & Embarked Columns\n",
    "- Convert Categorial features to numerical one as Sex & Embarked Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Survived  Pclass     Sex   Age  SibSp  Parch     Fare Embarked\n",
       "0         0       3    male  22.0      1      0   7.2500        S\n",
       "1         1       1  female  38.0      1      0  71.2833        C\n",
       "2         1       3  female  26.0      0      0   7.9250        S\n",
       "3         1       1  female  35.0      1      0  53.1000        S\n",
       "4         0       3    male  35.0      0      0   8.0500        S"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Drop unwanted features\n",
    "df_train = df_train.drop(['PassengerId', 'Name', 'Ticket', 'Cabin'], axis=1)\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Survived    0\n",
       "Pclass      0\n",
       "Sex         0\n",
       "Age         0\n",
       "SibSp       0\n",
       "Parch       0\n",
       "Fare        0\n",
       "Embarked    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fill missing data: \n",
    "\n",
    "# Age with the mean\n",
    "age_mean = df_train[['Age']].mean()\n",
    "df_train[['Age']] = df_train[['Age']].fillna(value=age_mean)\n",
    "\n",
    "# Embarked with most frequent value\n",
    "embarked_frequent = df_train['Embarked'].value_counts().idxmax()\n",
    "df_train[['Embarked']] = df_train[['Embarked']].fillna(value=embarked_frequent)\n",
    "\n",
    "df_train.isnull().sum() # check after filling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Survived  Pclass  Sex   Age  SibSp  Parch     Fare  Embarked\n",
       "0         0       3    0  22.0      1      0   7.2500         0\n",
       "1         1       1    1  38.0      1      0  71.2833         1\n",
       "2         1       3    1  26.0      0      0   7.9250         0\n",
       "3         1       1    1  35.0      1      0  53.1000         0\n",
       "4         0       3    0  35.0      0      0   8.0500         0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert categorical features into numeric by mapping the categories to some index\n",
    "df_train['Sex'] = df_train['Sex'].map({'male': 0, 'female': 1}).astype(int)\n",
    "df_train['Embarked'] = df_train['Embarked'].map({'S': 0, 'C': 1, 'Q': 2}).astype(int)\n",
    "\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Now we gonna define our inputs and outputs as a numpys array\n",
    "- Then we make train-validation split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X contains all columns except 'Survived'  \n",
    "# drop the survived column and convert it to numpy using values function\n",
    "X = df_train.drop(['Survived'], axis=1).values.astype(float)\n",
    "\n",
    "# Y is just the 'Survived' column\n",
    "Y = df_train['Survived'].values.astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Nice practice we need to normalize our dataset\n",
    "- We will normalize and split our dataset using sklearn library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing sklearn to normalize and split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# split our dataset to train/dev split with 20% validaton splitting\n",
    "X_train, X_val, Y_train, Y_val = train_test_split(X, Y, test_size=0.2, random_state=seed)\n",
    "\n",
    "# define our scaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# fit and transform the training data\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "\n",
    "# then normalize the validation data\n",
    "X_val = scaler.transform(X_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Can You prepare the test data yourself like the preprocessing we did on the training data ?! try it ?! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pclass       0\n",
      "Sex          0\n",
      "Age         86\n",
      "SibSp        0\n",
      "Parch        0\n",
      "Fare         1\n",
      "Embarked     0\n",
      "dtype: int64\n",
      "Pclass      0\n",
      "Sex         0\n",
      "Age         0\n",
      "SibSp       0\n",
      "Parch       0\n",
      "Fare        0\n",
      "Embarked    0\n",
      "dtype: int64\n",
      "             Pclass  Sex   Age  SibSp  Parch     Fare  Embarked\n",
      "PassengerId                                                    \n",
      "892               3    0  34.5      0      0   7.8292         2\n",
      "893               3    1  47.0      1      0   7.0000         0\n",
      "894               2    0  62.0      0      0   9.6875         2\n",
      "895               3    0  27.0      0      0   8.6625         0\n",
      "896               3    1  22.0      1      1  12.2875         0\n"
     ]
    }
   ],
   "source": [
    "# drop unwanted columns like train data\n",
    "df_test = df_test.drop(['Name', 'Ticket', 'Cabin'], axis=1)\n",
    "\n",
    "print(df_test.isnull().sum()) # check after filling\n",
    "# Fill missing data: \n",
    "\n",
    "# Age with the mean\n",
    "\n",
    "# check after filling\n",
    "\n",
    "# Convert categorical features into numeric by mapping the categories to some index\n",
    "\n",
    "print(df_test.head()) # check after preprocessing test data\n",
    "\n",
    "# get the numpy of the test from the dataframe\n",
    "X_test = df_test.values.astype(float)\n",
    "\n",
    "# normalize it like the training data\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (712, 7), dtype: float64\n",
      "X_val shape: (179, 7), dtype: float64\n",
      "Y_train shape: (712,), dtype: int64\n",
      "Y_val shape: (179,), dtype: int64\n",
      "X_test shape: (418, 7), dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# checking the shapes and the types of the numpy arrays\n",
    "print(\"X_train shape: {}, dtype: {}\".format(X_train.shape, X_train.dtype))\n",
    "print(\"X_val shape: {}, dtype: {}\".format(X_val.shape, X_val.dtype))\n",
    "print(\"Y_train shape: {}, dtype: {}\".format(Y_train.shape, Y_train.dtype))\n",
    "print(\"Y_val shape: {}, dtype: {}\".format(Y_val.shape, Y_val.dtype))\n",
    "print(\"X_test shape: {}, dtype: {}\".format(X_test.shape, X_test.dtype))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Can you tell what is the 7 Columns ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here We have our dataset is prepared very well and ready for training with keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Design Neural Networks with keras\n",
    "- In this notebook, we will use and understand very well the functional API of keras for creating models.\n",
    "\n",
    "#### Here some notes you should take care of.\n",
    "- A layer instance is callable (on a tensor), and it returns a tensor\n",
    "\n",
    "```\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, Dense\n",
    "\n",
    "a = Input(shape=(32,))\n",
    "b = Dense(32)(a)\n",
    "model = Model(inputs=a, outputs=b)\n",
    "```\n",
    "\n",
    "- This model will include all layers required in the computation of b given a."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/moemen/miniconda3/envs/dl3/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n"
     ]
    }
   ],
   "source": [
    "# import some important layers we will use to build our network\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, Dense\n",
    "\n",
    "# describing the layers of the neural network\n",
    "input_features = Input(shape=(7,)) # the 7 columns which is our features of the input\n",
    "\n",
    "########################\n",
    "# Describe your neural network here\n",
    "########################\n",
    "\n",
    "# output layer\n",
    "logits = Dense(1, activation='sigmoid')(None) # the prediction using sigmoid activation\n",
    "\n",
    "# Finalizing the model by specifying the inputs and the outputs\n",
    "model = Model(inputs=input_features, outputs=logits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's define our hyperparameters\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Here i will get you some examples of optimizers, losses and metrics\n",
    "## Optimizers\n",
    "- SGD\n",
    "- RMSProp\n",
    "- Adam\n",
    "## losses\n",
    "- mean_square_error\n",
    "- mean_absolute_error\n",
    "- categorical_crossentropy\n",
    "- hinge\n",
    "- binary_crossentropy (which is the most suitable loss function for our problem)\n",
    "## Metrics\n",
    "- A metric is a function that is used to judge the performance of your model. Metric functions are to be supplied in the metrics parameter when a model is compiled.\n",
    "- we can put any loss function in the metrics also to judge the performance\n",
    "- accuray (we will use it)\n",
    "- top_k_categorical_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/moemen/miniconda3/envs/dl3/lib/python3.6/site-packages/tensorflow_core/python/ops/nn_impl.py:183: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    }
   ],
   "source": [
    "# import the optimizer, loss functions and metrics\n",
    "\n",
    "from keras.callbacks.tensorboard_v1 import TensorBoard\n",
    "\n",
    "# define our optimizer\n",
    "\n",
    "# compile our using our defined optimizer, loss and  metric\n",
    "\n",
    "# we need a visualization for loss and accuracy \n",
    "# so we gonna use tensorboard visualization from keras callbacks APIs\n",
    "tensorboard_callback = TensorBoard(log_dir='./logs', batch_size=batch_size,\n",
    "                                   write_graph=True, update_freq='epoch')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we are ready to train our Neural Network\n",
    "\n",
    "#### Training in keras\n",
    "\n",
    "```\n",
    "fit(x=None, y=None, batch_size=None, epochs=1, verbose=1, callbacks=None, validation_split=0.0, validation_data=None, shuffle=True, class_weight=None, sample_weight=None, initial_epoch=0, steps_per_epoch=None, validation_steps=None, validation_freq=1, max_queue_size=10, workers=1, use_multiprocessing=False)\n",
    "```\n",
    "\n",
    "Fit function is the main function in keras which is responsible for training your models.\n",
    "You need to understand it very wellto be able to customize your training and control it very well.\n",
    "\n",
    "Don't forget to get the history returned from the fit function to visualize the training process (accuracy, loss, etc.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/moemen/miniconda3/envs/dl3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "Train on 712 samples, validate on 179 samples\n",
      "WARNING:tensorflow:From /home/moemen/miniconda3/envs/dl3/lib/python3.6/site-packages/keras/callbacks/tensorboard_v1.py:200: The name tf.summary.merge_all is deprecated. Please use tf.compat.v1.summary.merge_all instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/moemen/miniconda3/envs/dl3/lib/python3.6/site-packages/keras/callbacks/tensorboard_v1.py:203: The name tf.summary.FileWriter is deprecated. Please use tf.compat.v1.summary.FileWriter instead.\n",
      "\n",
      "Epoch 1/10\n",
      " - 3s - loss: 0.8601 - accuracy: 0.3652 - val_loss: 0.8081 - val_accuracy: 0.3799\n",
      "WARNING:tensorflow:From /home/moemen/miniconda3/envs/dl3/lib/python3.6/site-packages/keras/callbacks/tensorboard_v1.py:343: The name tf.Summary is deprecated. Please use tf.compat.v1.Summary instead.\n",
      "\n",
      "Epoch 2/10\n",
      " - 0s - loss: 0.7719 - accuracy: 0.4228 - val_loss: 0.7506 - val_accuracy: 0.4469\n",
      "Epoch 3/10\n",
      " - 0s - loss: 0.7215 - accuracy: 0.4986 - val_loss: 0.7019 - val_accuracy: 0.5587\n",
      "Epoch 4/10\n",
      " - 0s - loss: 0.6675 - accuracy: 0.6306 - val_loss: 0.6607 - val_accuracy: 0.5922\n",
      "Epoch 5/10\n",
      " - 0s - loss: 0.6400 - accuracy: 0.6531 - val_loss: 0.6250 - val_accuracy: 0.6369\n",
      "Epoch 6/10\n",
      " - 0s - loss: 0.6063 - accuracy: 0.6938 - val_loss: 0.5958 - val_accuracy: 0.6816\n",
      "Epoch 7/10\n",
      " - 0s - loss: 0.5764 - accuracy: 0.7205 - val_loss: 0.5703 - val_accuracy: 0.7039\n",
      "Epoch 8/10\n",
      " - 0s - loss: 0.5527 - accuracy: 0.7303 - val_loss: 0.5498 - val_accuracy: 0.7095\n",
      "Epoch 9/10\n",
      " - 0s - loss: 0.5311 - accuracy: 0.7654 - val_loss: 0.5312 - val_accuracy: 0.7430\n",
      "Epoch 10/10\n",
      " - 0s - loss: 0.5182 - accuracy: 0.7669 - val_loss: 0.5160 - val_accuracy: 0.7709\n"
     ]
    }
   ],
   "source": [
    "# training our model with our hyperparameters\n",
    "# and get the history\n",
    "history = model.fit(X_train, Y_train, batch_size=batch_size, epochs=num_epochs,\n",
    "                    validation_data=(X_val,Y_val), callbacks=[tensorboard_callback], verbose=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prediction shape: (418, 1),  dtype: float32\n",
      "prediction_submission shape: (418,),  dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# get the prediction of the model on the test data\n",
    "\n",
    "\n",
    "print(\"prediction shape: {},  dtype: {}\".format(prediction.shape, prediction.dtype))\n",
    "# choose whether one or zero submission\n",
    "prediction_submission = (prediction > 0.5).astype(int).ravel()\n",
    "print(\"prediction_submission shape: {},  dtype: {}\".format(prediction_submission.shape, prediction_submission.dtype))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the submission for kaggle\n",
    "submission = pd.DataFrame({\n",
    "    'PassengerId': df_test.index,\n",
    "    'Survived': prediction_submission,\n",
    "})\n",
    "\n",
    "submission.sort_values('PassengerId', inplace=True)    \n",
    "submission.to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Suggistive Experiments\n",
    "Some hints:\n",
    "- use adam\n",
    "- try kernal regularizers\n",
    "- try different kernel initializers\n",
    "- use dropout\n",
    "- try to decrease the number of dense layers\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exp1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 712 samples, validate on 179 samples\n",
      "Epoch 1/30\n",
      " - 0s - loss: 0.6737 - accuracy: 0.5983 - val_loss: 0.6062 - val_accuracy: 0.7933\n",
      "Epoch 2/30\n",
      " - 0s - loss: 0.5981 - accuracy: 0.7374 - val_loss: 0.5489 - val_accuracy: 0.7654\n",
      "Epoch 3/30\n",
      " - 0s - loss: 0.5433 - accuracy: 0.7711 - val_loss: 0.5068 - val_accuracy: 0.7765\n",
      "Epoch 4/30\n",
      " - 0s - loss: 0.4924 - accuracy: 0.8020 - val_loss: 0.4798 - val_accuracy: 0.7877\n",
      "Epoch 5/30\n",
      " - 0s - loss: 0.4788 - accuracy: 0.7837 - val_loss: 0.4628 - val_accuracy: 0.7765\n",
      "Epoch 6/30\n",
      " - 0s - loss: 0.4542 - accuracy: 0.8104 - val_loss: 0.4551 - val_accuracy: 0.7709\n",
      "Epoch 7/30\n",
      " - 0s - loss: 0.4622 - accuracy: 0.7753 - val_loss: 0.4546 - val_accuracy: 0.7765\n",
      "Epoch 8/30\n",
      " - 0s - loss: 0.4504 - accuracy: 0.8174 - val_loss: 0.4581 - val_accuracy: 0.7821\n",
      "Epoch 9/30\n",
      " - 0s - loss: 0.4568 - accuracy: 0.8104 - val_loss: 0.4604 - val_accuracy: 0.7765\n",
      "Epoch 10/30\n",
      " - 0s - loss: 0.4394 - accuracy: 0.8104 - val_loss: 0.4627 - val_accuracy: 0.7765\n",
      "Epoch 11/30\n",
      " - 0s - loss: 0.4294 - accuracy: 0.8202 - val_loss: 0.4607 - val_accuracy: 0.7821\n",
      "Epoch 12/30\n",
      " - 0s - loss: 0.4211 - accuracy: 0.8258 - val_loss: 0.4614 - val_accuracy: 0.7821\n",
      "Epoch 13/30\n",
      " - 0s - loss: 0.4315 - accuracy: 0.8146 - val_loss: 0.4596 - val_accuracy: 0.7877\n",
      "Epoch 14/30\n",
      " - 0s - loss: 0.4332 - accuracy: 0.8132 - val_loss: 0.4603 - val_accuracy: 0.7989\n",
      "Epoch 15/30\n",
      " - 0s - loss: 0.4299 - accuracy: 0.8188 - val_loss: 0.4597 - val_accuracy: 0.7933\n",
      "Epoch 16/30\n",
      " - 0s - loss: 0.4125 - accuracy: 0.8272 - val_loss: 0.4589 - val_accuracy: 0.7933\n",
      "Epoch 17/30\n",
      " - 0s - loss: 0.4111 - accuracy: 0.8258 - val_loss: 0.4549 - val_accuracy: 0.7933\n",
      "Epoch 18/30\n",
      " - 0s - loss: 0.4300 - accuracy: 0.8230 - val_loss: 0.4542 - val_accuracy: 0.7989\n",
      "Epoch 19/30\n",
      " - 0s - loss: 0.4290 - accuracy: 0.8301 - val_loss: 0.4580 - val_accuracy: 0.7821\n",
      "Epoch 20/30\n",
      " - 0s - loss: 0.4108 - accuracy: 0.8287 - val_loss: 0.4582 - val_accuracy: 0.7821\n",
      "Epoch 21/30\n",
      " - 0s - loss: 0.4199 - accuracy: 0.8202 - val_loss: 0.4569 - val_accuracy: 0.7933\n",
      "Epoch 22/30\n",
      " - 0s - loss: 0.4296 - accuracy: 0.8244 - val_loss: 0.4547 - val_accuracy: 0.7933\n",
      "Epoch 23/30\n",
      " - 0s - loss: 0.4167 - accuracy: 0.8216 - val_loss: 0.4557 - val_accuracy: 0.8045\n",
      "Epoch 24/30\n",
      " - 0s - loss: 0.4351 - accuracy: 0.8188 - val_loss: 0.4516 - val_accuracy: 0.7989\n",
      "Epoch 25/30\n",
      " - 0s - loss: 0.4129 - accuracy: 0.8244 - val_loss: 0.4512 - val_accuracy: 0.8045\n",
      "Epoch 26/30\n",
      " - 0s - loss: 0.4100 - accuracy: 0.8230 - val_loss: 0.4503 - val_accuracy: 0.7989\n",
      "Epoch 27/30\n",
      " - 0s - loss: 0.4202 - accuracy: 0.8202 - val_loss: 0.4513 - val_accuracy: 0.7989\n",
      "Epoch 28/30\n",
      " - 0s - loss: 0.4195 - accuracy: 0.8230 - val_loss: 0.4543 - val_accuracy: 0.7933\n",
      "Epoch 29/30\n",
      " - 0s - loss: 0.4291 - accuracy: 0.8174 - val_loss: 0.4558 - val_accuracy: 0.7933\n",
      "Epoch 30/30\n",
      " - 0s - loss: 0.4045 - accuracy: 0.8371 - val_loss: 0.4570 - val_accuracy: 0.7933\n",
      "prediction shape: (418, 1),  dtype: float32\n",
      "prediction_submission shape: (418,),  dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# import some important layers we will use to build our network\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, Dense, Dropout, ReLU\n",
    "# import the optimizer, loss functions and metrics\n",
    "from keras.optimizers import Adam\n",
    "from keras.regularizers import l2\n",
    "from keras.losses import BinaryCrossentropy\n",
    "from keras.callbacks.tensorboard_v1 import TensorBoard\n",
    "\n",
    "# describing the layers of the neural network\n",
    "\n",
    "# Finalizing the model by specifying the inputs and the outputs\n",
    "\n",
    "# Let's define our hyperparameters\n",
    "\n",
    "\n",
    "# define our optimizer\n",
    "\n",
    "# compile our using our defined optimizer, binary_crossentropy loss and accuracy metric\n",
    "\n",
    "\n",
    "# we need a visualization for loss and accuracy \n",
    "# so we gonna use tensorboard visualization from keras callbacks APIs\n",
    "tensorboard_callback = TensorBoard(log_dir='./logs_moemen', batch_size=batch_size,\n",
    "                                   write_graph=True, update_freq='epoch')\n",
    "\n",
    "# training our model with our hyperparameters\n",
    "# and get the history\n",
    "\n",
    "\n",
    "# get the prediction of the model on the test data\n",
    "\n",
    "\n",
    "\n",
    "print(\"prediction shape: {},  dtype: {}\".format(prediction.shape, prediction.dtype))\n",
    "# choose whether one or zero submission\n",
    "prediction_submission = (prediction > 0.5).astype(int).ravel()\n",
    "print(\"prediction_submission shape: {},  dtype: {}\".format(prediction_submission.shape,\n",
    "                                                           prediction_submission.dtype))\n",
    "\n",
    "# create the submission for kaggle\n",
    "submission = pd.DataFrame({\n",
    "    'PassengerId': df_test.index,\n",
    "    'Survived': prediction_submission,\n",
    "})\n",
    "submission.sort_values('PassengerId', inplace=True)    \n",
    "submission.to_csv('submission_moemen.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exp2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import some important layers we will use to build our network\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, Dense, Dropout, ReLU\n",
    "# import the optimizer, loss functions and metrics\n",
    "from keras.optimizers import Adam\n",
    "from keras.regularizers import l2\n",
    "from keras.losses import BinaryCrossentropy\n",
    "from keras.callbacks.tensorboard_v1 import TensorBoard\n",
    "\n",
    "# describing the layers of the neural network\n",
    "\n",
    "# Finalizing the model by specifying the inputs and the outputs\n",
    "\n",
    "# Let's define our hyperparameters\n",
    "\n",
    "\n",
    "# define our optimizer\n",
    "\n",
    "# compile our using our defined optimizer, binary_crossentropy loss and accuracy metric\n",
    "\n",
    "\n",
    "# we need a visualization for loss and accuracy \n",
    "# so we gonna use tensorboard visualization from keras callbacks APIs\n",
    "tensorboard_callback = TensorBoard(log_dir='./logs_moemen', batch_size=batch_size,\n",
    "                                   write_graph=True, update_freq='epoch')\n",
    "\n",
    "# training our model with our hyperparameters\n",
    "# and get the history\n",
    "\n",
    "\n",
    "# get the prediction of the model on the test data\n",
    "\n",
    "\n",
    "\n",
    "print(\"prediction shape: {},  dtype: {}\".format(prediction.shape, prediction.dtype))\n",
    "# choose whether one or zero submission\n",
    "prediction_submission = (prediction > 0.5).astype(int).ravel()\n",
    "print(\"prediction_submission shape: {},  dtype: {}\".format(prediction_submission.shape,\n",
    "                                                           prediction_submission.dtype))\n",
    "\n",
    "# create the submission for kaggle\n",
    "submission = pd.DataFrame({\n",
    "    'PassengerId': df_test.index,\n",
    "    'Survived': prediction_submission,\n",
    "})\n",
    "submission.sort_values('PassengerId', inplace=True)    \n",
    "submission.to_csv('submission_moemen.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
